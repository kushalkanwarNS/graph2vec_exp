{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9a3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from model import SkipGramModel\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d1f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"NCI1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff649b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./'+dataset+'/graph_voc_3.json', 'rb') as f:\n",
    "    graph_enc = pickle.load(f)\n",
    "\n",
    "sub_graph_voc = []\n",
    "for g in list(graph_enc.keys()):\n",
    "    sub_graph_voc.extend(graph_enc[g])\n",
    "\n",
    "min_cnt = 5\n",
    "\n",
    "sub_graph_vocab = dict(Counter(sub_graph_voc))\n",
    "sub_graph_vocab = {i:sub_graph_vocab[i] for i in list(sub_graph_vocab.keys()) if sub_graph_vocab[i]>=min_cnt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03647b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in list(graph_enc.keys()):\n",
    "    graph_enc[g] = [x for x in graph_enc[g] if x in list(sub_graph_vocab.keys())]\n",
    "\n",
    "id_to_sub_graph = {i:list(sub_graph_vocab.keys())[i] for i in range(len(sub_graph_vocab))}\n",
    "sub_graph_to_id = {id_to_sub_graph[i]:i for i in list(id_to_sub_graph.keys())}\n",
    "\n",
    "model_1 = SkipGramModel(len(graph_enc), len(id_to_sub_graph), 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abce7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sample_table():\n",
    "    sample_table = []\n",
    "    sample_table_size = 1e8\n",
    "    pow_frequency = np.array(list(sub_graph_vocab.values())) ** 0.75\n",
    "    words_pow = sum(pow_frequency)\n",
    "    ratio = pow_frequency / words_pow\n",
    "    count = np.round(ratio * sample_table_size)\n",
    "    for wid, c in enumerate(count):\n",
    "        sample_table += [sub_graph_to_id[list(sub_graph_vocab.keys())[wid]]] * int(c)\n",
    "    sample_table = np.array(sample_table)\n",
    "    return sample_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc378701",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_table = init_sample_table()\n",
    "neg_count = 2\n",
    "epoch = 20\n",
    "\n",
    "opt = optim.SparseAdam(model_1.parameters(), lr=0.0001)\n",
    "model_1.train()\n",
    "\n",
    "cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    cuda = True\n",
    "    model_1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c11666",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1581868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0\tloss - 2.0138826\n",
      "epoch - 1\tloss - 1.6570077\n",
      "epoch - 2\tloss - 1.2493625\n",
      "epoch - 3\tloss - 0.97931015\n",
      "epoch - 4\tloss - 0.81560194\n",
      "epoch - 5\tloss - 0.70842934\n",
      "epoch - 6\tloss - 0.6298165\n",
      "epoch - 7\tloss - 0.57592624\n",
      "epoch - 8\tloss - 0.5366204\n",
      "epoch - 9\tloss - 0.50597227\n",
      "epoch - 10\tloss - 0.4805988\n",
      "epoch - 11\tloss - 0.4631515\n",
      "epoch - 12\tloss - 0.4480258\n",
      "epoch - 13\tloss - 0.43521816\n",
      "epoch - 14\tloss - 0.4254279\n",
      "epoch - 15\tloss - 0.41492504\n",
      "epoch - 16\tloss - 0.4112482\n",
      "epoch - 17\tloss - 0.40363556\n",
      "epoch - 18\tloss - 0.39864045\n",
      "epoch - 19\tloss - 0.3947498\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    for j in range(len(graph_enc)):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # doc_id = np.random.randint(1, len(graph_enc))\n",
    "        doc_id = j\n",
    "        if len(graph_enc[doc_id + 1]) == 0:\n",
    "            continue\n",
    "        doc_u = torch.tensor([doc_id], dtype=torch.long, requires_grad=False)\n",
    "\n",
    "        pos_v = [sub_graph_to_id[x] for x in graph_enc[doc_id + 1]]\n",
    "        loss = []\n",
    "        for p in pos_v:\n",
    "\n",
    "            while (True):\n",
    "                neg_v = np.random.choice(sample_table, size=(neg_count)).tolist()\n",
    "                if p not in neg_v:\n",
    "                    break\n",
    "\n",
    "            pos = torch.tensor([p], dtype=torch.long, requires_grad=False)\n",
    "            neg_v = torch.tensor(neg_v, dtype=torch.long, requires_grad=False)\n",
    "\n",
    "            if cuda:\n",
    "                doc_u = doc_u.cuda()\n",
    "                pos = pos.cuda()\n",
    "                neg_v = neg_v.cuda()\n",
    "\n",
    "            loss_val = model_1(doc_u, pos, neg_v)\n",
    "\n",
    "            # print(str(i)+'   '+str(loss_val))\n",
    "            loss.append(loss_val.data.cpu().numpy())\n",
    "            loss_val.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if doc_id not in list(loss_g.keys()):\n",
    "            loss_g[doc_id] = [np.mean(loss)]\n",
    "        else:\n",
    "            loss_g[doc_id].append(np.mean(loss))\n",
    "\n",
    "    l = np.mean([loss_g[k][i] for k in list(loss_g.keys())])\n",
    "\n",
    "    print('epoch - ' + str(i) + '\\tloss - ' + str(l))\n",
    "\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d20b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0138826, 1.6570077, 1.2493625, 0.97931015, 0.81560194, 0.70842934, 0.6298165, 0.57592624, 0.5366204, 0.50597227, 0.4805988, 0.4631515, 0.4480258, 0.43521816, 0.4254279, 0.41492504, 0.4112482, 0.40363556, 0.39864045, 0.3947498]\n"
     ]
    }
   ],
   "source": [
    "iter_loss = [np.mean([loss_g[x][i] for x in list(loss_g.keys())]) for i in range(epoch)]\n",
    "print(iter_loss)\n",
    "\n",
    "with open('./' + dataset + '/loss.json', 'wb') as f:\n",
    "    pickle.dump(loss_g, f)\n",
    "\n",
    "with open('./' + dataset + '/iter_loss.json', 'wb') as f:\n",
    "    pickle.dump(iter_loss, f)\n",
    "\n",
    "model_1.save_embedding(cuda, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92882d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba8f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
